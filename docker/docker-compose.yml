version: '3.7'
services:
  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - "2181:2181"

  kafka:
    image: wurstmeister/kafka:latest
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    expose:
      - "9093"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9093,OUTSIDE://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://0.0.0.0:9093,OUTSIDE://0.0.0.0:9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_DELETE_TOPIC_ENABLE: "true"
    # NOTE kafka starts up with no topics - topics are created by flink jobs
    # this could be changed by specifying persistent volume (NOTE: this is also required for zookeeper,
    # otherwise topics are effectively gone even if the log files still exist!)

  jobmanager:
    image: flink:1.7.2-scala_2.12
    expose:
      - "6123"
      - "9249" # to publish prometheus metrics
    ports:
      - "8082:8081" # map to 8082 on host, to differentiate from the dev minicluster UI (on 8081)
    command: jobmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager
      - MVRS_DSPA_KAFKA_BROKERS=kafka:9093         # instead of localhost:9092 when connecting from local machine
      - MVRS_DSPA_ELASTICSEARCH_NODE=elasticsearch # instead of localhost when connecting from local machine
      - MVRS_DSPA_DATA_DIR=file:///usr/share/flink/data
    volumes:
      - ./flink/conf/flink-conf.yaml:/opt/flink/conf/flink-conf.yaml
      - ./flink/lib/flink-metrics-prometheus-1.7.2.jar:/opt/flink/lib/flink-metrics-prometheus-1.7.2.jar
      - type: bind                                 # bind mapping for test data
        source: ${MVRS_DSPA_DATA_DIR_HOST:-./data} # default: ./data
        target: /usr/share/flink/data              # path in container

  taskmanager:
    image:  flink:1.7.2-scala_2.12
    expose:
      - "6121"
      - "6122"
      - "9249" # to publish prometheus metrics
    depends_on:
      - jobmanager
    command: taskmanager
    links:
      - "jobmanager:jobmanager"
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager
      - MVRS_DSPA_KAFKA_BROKERS=kafka:9093         # instead of localhost:9092 when connecting from local machine
      - MVRS_DSPA_ELASTICSEARCH_NODE=elasticsearch # instead of localhost when connecting from local machine
      - MVRS_DSPA_DATA_DIR=file:///usr/share/flink/data
    volumes:
      - ./flink/conf/flink-conf.yaml:/opt/flink/conf/flink-conf.yaml
      - ./flink/lib/flink-metrics-prometheus-1.7.2.jar:/opt/flink/lib/flink-metrics-prometheus-1.7.2.jar
      - type: bind                                 # bind mapping for test data
        source: ${MVRS_DSPA_DATA_DIR_HOST:-./data} # default: ./data
        target: /usr/share/flink/data              # path in container

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:6.7.2
    environment:
      - cluster.name=docker-cluster
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - type: volume
        source: logs
        target: /var/log
      - type: volume
        source: esdata1
        target: /usr/share/elasticsearch/data
    ports:
      - "9200:9200"

  kibana:
    image: docker.elastic.co/kibana/kibana:6.7.2
    ports:
      - "5602:5601"
    depends_on:
      - elasticsearch

  prometheus:
    image: quay.io/prometheus/prometheus:v2.8.1
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    command: "--config.file=/etc/prometheus/prometheus.yml --storage.tsdb.path=/prometheus"
    ports:
      - 9090:9090
    depends_on:
      - exporter
  exporter:
    image: prom/node-exporter:latest
    ports:
      - "9100:9100"
  #    network_mode: host

  grafana:
    image: grafana/grafana
    ports:
      - "8080:3000"
    depends_on:
      - prometheus
    volumes:
      - grafana_data:/var/lib/grafana                           # to keep dashboards etc.
      - ./grafana/custom.ini:/usr/share/grafana/conf/custom.ini # TODO verify that this is loaded (see note on https://grafana.com/docs/installation/configuration/)
      - ./grafana/provisioning/:/etc/grafana/provisioning/      # NOTE not sure what this will be useful for...
  # uid/pwd?

volumes:
  esdata1:
  logs:
  grafana_data:
